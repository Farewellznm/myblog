---
title: "Seurat包（2）：整合数据"
author: "Zhaojn"
date: "2021-11-30"
category: 组学分析
tags: 
- 组学分析
output: html_document
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="单细胞数据整合的两个方面" class="section level1">
<h1>单细胞数据整合的两个方面</h1>
<p>1
如何将同一组细胞类型基于不同技术平台或由不同批次实验产生的测序数据进行修正与合并？</p>
<p>2 如何将同一组细胞类型的多组学特征信息整合从而完整描绘细胞状态？
<a href="DOI:https://doi.org/10.1016/j.cell.2019.05.031" class="uri">DOI:https://doi.org/10.1016/j.cell.2019.05.031</a> SueratV3的文章</p>
<p>作者分析了这4种方法对一个包含8个独立亚数据集的胰岛单细胞RNA测序数据集的整合效果。经由UMAP降维和可视化</p>
<ol style="list-style-type: decimal">
<li><p>SueratV2(canonical correlation analysis, CCA)</p></li>
<li><p>mnnCorrect (mutual nearest neighbor, MNN)</p></li>
<li><p>SueratV3(新算法综合了前述两类分别基于CCA降维和MNN搜索互近邻的方案)</p></li>
<li><p>scanorama</p></li>
</ol>
<p>为了定量分析上述由聚类模式展示的不同算法在数据修正和整合上的表现差异，研究者试图从两个角度对其进行考察：一是整合后来源于不同批次的数据点的混杂程度，二是整合后同一批次中的数据点的原有聚类模式的保留。这两个参数分别表征了数据整合对批次效应的去除程度和对真实生物学效应的保存程度。</p>
<p>Integration 聚类特征应由真实的生物学特征决定而不是由批次效应决定</p>
<pre class="r"><code>#可以写到记事本里.r用Source快速library
library(Seurat)
library(SeuratData)
library(patchwork)</code></pre>
<pre class="r"><code># install dataset，这里如果因为网速下载失败可以手动安装
InstallData(&quot;ifnb&quot;)
 #查询R包安装位置，解压好放到library
.libPaths()
# load dataset
LoadData(&quot;ifnb&quot;)
# split the dataset into a list of two seurat objects (stim and CTRL)
ifnb.list &lt;- SplitObject(ifnb, split.by = &quot;stim&quot;)

# normalize and identify variable features for each dataset independently
ifnb.list &lt;- lapply(X = ifnb.list, FUN = function(x) {
    x &lt;- NormalizeData(x)#对数据进行标准化
    x &lt;- FindVariableFeatures(x, selection.method = &quot;vst&quot;, nfeatures = 2000)#筛选高变基因
})
# select features that are repeatedly variable across datasets for integration
#选择数据集间重复可变基因，作为下一步的anchor. features
features &lt;- SelectIntegrationFeatures(object.list = ifnb.list)</code></pre>
<p>#数据整合SueratV3</p>
<p>Seurat包的函数基本是函数名精准定位其功能，最后的数据整合所用到的函数就是IntegrateData，
其中的参数是anchorset，所以上一步就要FindIntegrationAnchors找到整合的锚定点，
FindIntegrationAnchors这个函数里面的参数有object.list =
，anchor.features = ，故其上一步是选features 和数学里的反证法好像。</p>
<pre class="r"><code>immune.anchors &lt;- FindIntegrationAnchors(object.list = ifnb.list, 
                                         anchor.features = features)
# this command creates an &#39;integrated&#39; data assay
immune.combined &lt;- IntegrateData(anchorset = immune.anchors)</code></pre>
</div>
<div id="fast-integration-using-reciprocal-pca-rpca" class="section level1">
<h1>Fast integration using reciprocal PCA (RPCA)</h1>
<p>用于整合 scRNA-seq 数据集</p>
<p>虽然命令列表几乎相同，但此流程要求用户在整合之前对每个数据集单独运行主成分分析
(PCA)。
<a href="https://satijalab.org/seurat/reference/FindIntegrationAnchors.html"><code>FindIntegrationAnchors()</code></a>。用户还应该在运行时将“reduction”参数设置为“rpca”</p>
<pre class="r"><code># load dataset
LoadData(&quot;ifnb&quot;)

# split the dataset into a list of two seurat objects (stim and CTRL)
ifnb.list &lt;- SplitObject(ifnb, split.by = &quot;stim&quot;)

# normalize and identify variable features for each dataset independently
ifnb.list &lt;- lapply(X = ifnb.list, FUN = function(x) {
    x &lt;- NormalizeData(x)
    x &lt;- FindVariableFeatures(x, selection.method = &quot;vst&quot;, nfeatures = 2000)
})

# select features that are repeatedly variable across datasets for integration run PCA on each
# dataset using these features
features &lt;- SelectIntegrationFeatures(object.list = ifnb.list)
ifnb.list &lt;- lapply(X = ifnb.list, FUN = function(x) {
    x &lt;- ScaleData(x, features = features, verbose = FALSE)
    x &lt;- RunPCA(x, features = features, verbose = FALSE)
})#对每个数据集单独运行主成分分析 (PCA)</code></pre>
<pre class="r"><code>immune.anchors &lt;- FindIntegrationAnchors(object.list = ifnb.list, anchor.features = features, reduction = &quot;rpca&quot;)#reduction”参数设置为“rpca”
# this command creates an &#39;integrated&#39; data assay
immune.combined &lt;- IntegrateData(anchorset = immune.anchors)</code></pre>
</div>
<div id="整合大型数据集的技巧" class="section level1">
<h1>整合大型数据集的技巧</h1>
<ul>
<li><p>创建要集成的 Seurat 对象列表</p>
<p>CreateSeuratObject()</p></li>
<li><p>standard normalization and variable feature selection</p></li>
</ul>
<pre><code>NormalizeData()

FindVariableFeatures()</code></pre>
<ul>
<li><p>select features for downstream integration, and run PCA on each
object in the list</p>
<p>SelectIntegrationFeatures()</p>
<p>ScaleData()</p>
<p>RunPCA()</p></li>
<li><p>整合数据集，并进行联合分析</p>
<p>FindIntegrationAnchors()</p>
<p>IntegrateData()</p></li>
</ul>
<p>##两个方法提高效率</p>
<p>Reciprocal PCA (RPCA)</p>
<p>Reference-based integration</p>
<pre class="r"><code>bm280k.data &lt;- Read10X_h5(&quot;../data/ica_bone_marrow_h5.h5&quot;)
bm280k &lt;- CreateSeuratObject(counts = bm280k.data, min.cells = 100, min.features = 500)
bm280k.list &lt;- SplitObject(bm280k, split.by = &quot;orig.ident&quot;)

bm280k.list &lt;- lapply(X = bm280k.list, FUN = function(x) {
    x &lt;- NormalizeData(x, verbose = FALSE)
    x &lt;- FindVariableFeatures(x, verbose = FALSE)
})

features &lt;- SelectIntegrationFeatures(object.list = bm280k.list)

bm280k.list &lt;- lapply(X = bm280k.list, FUN = function(x) {
    x &lt;- ScaleData(x, features = features, verbose = FALSE)
    x &lt;- RunPCA(x, features = features, verbose = FALSE)#这里
})

anchors &lt;- FindIntegrationAnchors(object.list = bm280k.list, reference = c(1, 2), reduction = &quot;rpca&quot;,
    dims = 1:50)#这里注意一下

bm280k.integrated &lt;- IntegrateData(anchorset = anchors, dims = 1:50)</code></pre>
</div>
